%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{ICFP} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption
\usepackage{syntax}

\begin{document}

%% Title information
\title[Short Title]{Pushdown Control-Flow Analysis via Refunctionalization (Functional Pearl)}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
\titlenote{with title note}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
\subtitle{Filling the Gap between Abstracting Abstract Machine and Abstracting Definitional Interpreter}        %% \subtitle is optional
\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  Abstracting abstract machines (AAM) is a systematic methodology 
  for constructing abstract interpreters that derived from concrete
  small-step abstract machines. Recent progress applies the same idea 
  on definitional interpreter and obtains a big-step 
  abstracting definitional interpreter (ADI) written in monadic style.
  Danvy shows the correspondence between concrete abstract machines and interpreters.
  But the relations between small-step abstracting abstract machines and 
  big-step abstracting definitional interpreters is not well studied.

  In this paper, we show their correspondence and how to syntactically transform small-step 
  abstracting abstract machines into big-step abstracting definitional 
  interpreters.
  The transformations include fusing, disentangling, refunctionalizing 
  and monadification (or un-CPS to direct-style). All of them properly handle the 
  collecting semantics and the non-determinism of abstract interpretation. 
  After each transformation, we also obtain an intermediary form of 
  abstract interpreter.
  Remarkably, follow the idea that evaluation contexts are defunctionalized 
  continuations, we reveal how precise call/return match in control-flow 
  analysis can be obtained by refunctionalizing a small-step abstracting 
  abstract machine,
  as well as explain how it been lost by defunctionalizing the higher-order
  continuations into an firts-order data type. 
  
  TODO: Maybe something Shiver's formulation of CFA in denotational style. 
 
\end{abstract}

%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{pushdown analysis, abstract interpretation, static analysis}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}

\subsection{Motivation}

\subsection{Contributions}

the essence of abstracting definitional interpreter.

\begin{itemize}
\item The main contribution of this paper is we fill the gap
  between small-step AAM and big-step ADI by developing a series of
  systematic transformations. The correspondence between abstract
  machines and interpreters exists not only in concrete semantics artifact,
  but also in abstract semantics artifact.
  Galois connection?

\item We present an abstract interpreter obtained from refunctionalizing
  an small-step abstracting abstract machine. 
  This abstract interpreter naturally has pushdown control-flow property
  since we represent the evaluation contexts of analyzed language using
  continuations of the meta-language, and therefore sequentialize the
  analyzing.
  We also analyze its termination, soundness and complexity.

\item Further, we show that defunctionalization and refunctionalization
  of abstract interpreters play important roles for call stack of analyzed language.
  Given this insight, we reveal that why small-step AAM has no pushdown
  control-flow property (if without extra effort), as well as explain
  that why ADI naturally extends pushdown control-flow property from its
  defining language.

\end{itemize}

\subsection{Outline}

\subsection{Style}

We use Scala language to demonstrate the idea and each step of transformations.
There are two main reasons to do so:
1) The code does not diminish the accuracy of the material
than formal and mathematical notations, 
which are heavily used in other papers in static analysis or semantics.
The Scala code in this paper can be easily back-translated into formal notations.
2) The code is also executable with only few changes, which make it particularly fit for 
presenting topic: syntactical transformations of programs.

\section{Background}

In this section, we first describe the target language we will
analyze and a concrete CESK machine as operational semantics for it.
Then we review some recent works in control-flow analysis for
higher-order languages:
1) abstracting abstract machines (AAM) as an abstract interpretation
counterpart of CESK machines, and
2) the precise call/return match problem in control-flow analysis and its existing solutions.
We will show in section 3 that the abstracting abstract machines form the basis of our transformations,
and call/return match is obtained during transformation.

\subsection{A-Normal Form $\lambda$-Calculus} \label{anfsyntax}

Traditionally, continuation-passing style (CPS) is a popular intermediate representation
for analyzing functional programs because of it exposes control transfer explicitly
and simplifies the analysis \cite{Shivers:1991:SSC:115865.115884, Shivers:1988:CFA:53990.54007}.
Here, we choose to use administrative normal form (ANF) which is a direct-style intermediate representation 
as target for clarity but without losing simplicity and generality.
Although we just show the core calculus language, but it can be easily extended
to support recursive bindings, conditionals, primitive types and operations on primitive types.
The transformations we will show in the rest of this paper
also work on abstract machines for plain, direct-style $\lambda$-calculus languages.
TODO: add letrec?

To begin, we now present the concrete syntax of a call-by-value $\lambda$-calculus language 
in ANF \cite{flanagan1993essence}.

\begin{verbatim}
e \in Exp ::= ae
            | (let ([x (f ae)]) e)
ae \in AExp ::= x
              | lam
lam \in Lam ::= (lambda (x) e)
x ... are variable names
\end{verbatim}

In ANF, all the function applications must be administrated in a \texttt{let} expression,
and then bounded to a variable name under current environment.
We can use \texttt{letrec} to create mutually recursive function bindings. But \texttt{letrec}
only accepts atomic expressions that appear at the right-hand side of a binding.
The atomic expressions $ae$ are either a variable, or a literal \texttt{lambda} term, which
both can be evaluated in a single step.

The abstract syntax can be straightforwardly described in Scala as follows:

\begin{verbatim}
sealed trait Expr
case class Binding(x: String, e: Expr)

case class Var(x: String) extends Expr
case class App(e1: Expr, e2: Expr) extends Expr
case class Lam(x: String, body: Expr) extends Expr
case class Let(x: String, e: App, body: Expr) extends Expr
\end{verbatim}

\subsection{CESK Machine} \label{cesk}

\subsubsection{Machine Components}

\textit{C}ontrol \textit{E}nvionment \textit{S}tore \textit{K}ontinuation (CESK) machine is an
abstract machine for describing semantics of and evaluating $\lambda$-calculus \cite{felleisen1987calculus}.
CESK machine models program execution as state transitions in a small-step fashion. As its name suggested,
a machine state has four components: 1) Control is the expression currently being evaluated.
2) Environment is the a map that contains the address of a variable that in the lexical
scope of control.
3) Store models the heap of a program, and it is also a map but maps from addresses to values.
The addresses are infinite numbers starting from 0.
In our toy language, the only category of value is closure, i.e., a function paired with an environment.
4) Continuation represents the program stack.

We show the Scala representations for the components of CESK machine.

\begin{verbatim}
type Addr = Int
type Env = Map[String, Addr]
type Store = Map[Addr, Storable]

abstract class Storable
case class Clos(v: Lam, env: Env) extends Storable

case class Frame(x: String, e: Expr, env: Env)
type Kont = List[Frame]

case class State(e: Expr, env: Env, store: Store, k: Kont)
\end{verbatim}

It is worth noting that the continuation class \texttt{Kont} is defined as a list of frames.
The frame class \texttt{Frame} stores the information of call-site, i.e., the information that
can be used to resume the interrupted computation.
A \texttt{Frame} constitutes of a variable name \texttt{x} to be bind later, a control expression
that resumes to, and its environment. (TODO: mention that frame list vs KArg/KFun)

\subsubsection{Single-step Transition}
Before go into describing how the machine evaluates expressions, we firstly define several helper functions.
As we mentioned in section \ref{anfsyntax}, the atomic expressions are either a variable, or
a literal \texttt{lambda} term. So the helper function \texttt{atomicEval} handles these two
cases and evaluates atomic expressions to closures in a straightforward way.
The \texttt{alloc} function generates a fresh address, and always allocates an unique integer under the domain
of store.
The \texttt{isAtomic} function is used as a predicate of whether the expression is atomic.

\begin{verbatim}
def atomicEval(e: Expr, env: Env, store: Store): Storable = e match {
  case Var(x) => store(env(x))
  case lam@Lam(x, body) => Clos(lam, env)
}
def alloc(store: Store): Addr = store.keys.size + 1
def isAtomic(e: Expr): Boolean = e.isInstanceOf[Var] || e.isInstanceOf[Lam]
\end{verbatim}

Now, we can faithfully describe the state transition function \texttt{step},
that given a machine state, function \texttt{step} determines its successor state.

\begin{verbatim}
def step(s: State): State = s match {
  case State(Let(x, App(f, ae), e), env, store, k) if isAtomic(ae) =>
    val Clos(Lam(v, body), env_c) = atomicEval(f, env, store)
    val addr = alloc(store)
    val new_env = env_c + (v -> addr)
    val new_store = store + (addr -> atomicEval(ae, env, store))
    val frame = Frame(x, e, env)
    State(body, new_env, new_store, frame::k)
  case State(ae, env, store, k) if isAtomic(ae) =>
    val Frame(x, e, env_k)::ks = k
    val addr = alloc(store)
    val new_env = env_k + (x -> addr)
    val new_store = store + (addr -> atomicEval(ae, env, store))
    State(e, new_env, new_store, ks)
}
\end{verbatim}

The first case is that the control of current state is a \texttt{Let} expression,
and its right-hand side is an function application.
By calling function \texttt{atomicEval}, we obtain the closure that callee \texttt{f} stands for.
The successor state's control then transfers to the \texttt{body} expression of closure,
with an updated environment and an update store. The new environment is extended
from closure's environment and mapped \texttt{v} to a fresh address \texttt{addr}.
The new store is extended with \texttt{addr} mapping to the value of \texttt{ae},
which is evaluated from \texttt{atomicEval}.
In the meanwhile, a new frame \texttt{frame} is pushed onto the stack \texttt{k}.
This \texttt{frame} contains the variable name \texttt{x} at left-hand side position of \texttt{Let},
the body expression of \texttt{Let}, and the lexical environment of the body expression.

The second case for \texttt{step} is the control is transferred to an atomic expression.
We extract the top frame of continuations firstly.
The control (that is an atomic expression) of current state is the evaluated term
that being bind to the variable \texttt{x} from the top frame.
The environment and store are updated with \texttt{x} mapping to the closure value of \texttt{ae}.
Then the successor state is transferred to expression \texttt{e} from the top frame,
which is the body of a \texttt{Let} expression, with the updated environment, store, and
the rest of stack \texttt{ks}.

\subsubsection{Valuation}

To run the program, we first use function \texttt{inject} to construct an initial machine
state given an expression \texttt{e}. The initial state contains an empty environment, 
store and stack.
\begin{verbatim}
def inject(e: Expr): State = State(e, Map(), Map(), Nil)
\end{verbatim}

Then the \texttt{drive} function is used to evaluate
to a final state by iteratively apply \texttt{step} on current state until we reach a state
that the control is an atomic expression and the continuation stack is empty.
And of course, we can extract the value from the final state at last.

\begin{verbatim}
def drive(s: State): State = s match {
  case State(ae, _, _, Nil) if isAtomic(ae) => s
  case _ => drive(step(s))
}
def eval(e: Expr): State = drive(inject(e))
\end{verbatim}

\subsection{Abstracting Abstract Machine} \label{aam}
Abstracting abstract machine (AAM) is a systematic methodology that derives sound 
abstract interpreters for higher-order functional languages from concrete 
abstract machines \cite{van2012systematic, van2010abstracting}. 
An abstracting abstract machine implements computable abstract semantics that 
approximates the runtime behaviors of programs.
Since the state space of concrete execution is possibly infinite,
so to analyze programs, the key insight of AAM approach is to allocate both bindings
and continuations on the store, and then bound the addresses space to be finite.
Thus the approximated machine-state space is finite, and computable.

In this section, we derive the abstracting abstract machine from concrete
CESK machines, and also show that how to instantiate
useful $k$-call-sensitive analysis.

\subsubsection{Machine Components}

Similar with CESK machines, the machine state of the AAM has a control expression,
an environment, a store and continuation, and in addition with a time-stamp.
But there are several notable differences of store between AAMs and concrete CESK machines.
In AAM, the store maps addresses to sets of values, so it stores all possible values
for a particular address. Thus the dereference an address becomes non-deterministic.
Also, the store performs a join rather than overwriting when updating elements of the store.
Third, the continuations are likewise allocated on store instead of formed a linked list,
and the continuation in a state then turns into a continuation address.

For clarity, we divide the store into binding store \texttt{BStore} and continuation store \texttt{KStore}. 
The binding store maps binding addresses to sets of closure values, and continuation store maps
continuation addresses to sets of continuations.
We define a generic class \texttt{Store[K,V]} that performs join when updating elements
in a store. By parameterizing \texttt{Store[K,V]} with \texttt{[BAddr, Storable]} and 
\texttt{[KAddr, Cont]}, we obtain \texttt{BStore} and \texttt{KStore}, perspectively.

TODO(rephrase): Note that the store is monotonic, the store is always growing and never becoming 
smaller. This property guarantees we eventually will find a fixed point.

\begin{verbatim}
case class Store[K,V](map: Map[K, Set[V]]) {
  def apply(addr: K): List[V] = map(addr).toList
  def update(addr: K, d: Set[V]): Store[K,V] = {
    val oldd = map.getOrElse(addr, Set())
    Store[K, V](map ++ Map(addr -> (d ++ oldd)))
  }
  def update(addr: K, sd: V): Store[K,V] = update(addr, Set(sd))
}
type BStore = Store[BAddr, Storable]
type KStore = Store[KAddr, Cont]
\end{verbatim}

The co-domain of binding stores \texttt{Storable} is the same
as we defined for CESK machines.
The co-domain of continuation stores \texttt{Cont} is comprised of 
a frame \texttt{Frame} and a continuation address \texttt{KAddr}.
To mimic the runtime call stack, \texttt{KAddr} plays the role of
representing the remaining stack frames.
TODO: talk about nondet of cont deref?

\begin{verbatim}
abstract class Storable 
case class Clos(v: Lam, env: Env) extends Storable

case class Frame(x: String, e: Expr, env: Env)
case class Cont(frame: Frame, kaddr: KAddr)
\end{verbatim}

As a consequence, the components of a state is also changed: 
the store is divided into binding store and continuation store;
the continuation stack becomes an address.
By dereferencing this address in continuation store, we can retrieve the 
actual transfer of controls. The definition of environment \texttt{Env}
remains the same.

\begin{verbatim}
case class State(e: Expr, env: Env, bstore: BStore, 
                 kstore: KStore, k: KAddr, time: Time)
\end{verbatim}

\subsubsection{Allocating Addresses}
Up to now, we did not describe much about the adresses in stores and the 
time-stamp \texttt{Time}.
But they are key ingredients to achieve analyses with different sensitivities,
as well as a finite state space analysis.
To effectively approximate the runtime behavior, a finite 
program contour \texttt{time} that encodes the program execution history is introduced.
Here, we use a list of execution contexts (expressions) to reprent that, and
as we will see in section \ref{kcfainst}, by using different \texttt{tick}
function on time we may obtain a family of analyses.

\begin{verbatim}
type Time = List[Expr]
\end{verbatim}

As we mentioned previously, the space of addresses is finite in AAM.
Binding addresses are parameterized by variable names and the time that creates this binding,
which are both finite.
Continuation addresses \texttt{KAddr} has two variants: 
1) \texttt{Halt} which corresponds to the empty stack, and
2) \texttt{ContAddr} consists of the entry expression of callee and the time that
creates this address, and they are also finite. 
(TODO: why target expression, allocation polyvariance)

\begin{verbatim}
case class BAddr(x: String, time: Time)

abstract class KAddr
case object Halt extends KAddr
case class ContAddr(tgt: Expr, time: Time) extends KAddr
\end{verbatim}

We use two helper functions \texttt{allocBind} and \texttt{allocKont} that will be used later
to allocate binding addresses and continuation addresses.

\begin{verbatim}
def allocBind(x: String, time: Time): BAddr = BAddr(x, time)
def allocKont(tgtExpr: Expr, time: Time): KAddr = ContAddr(tgtExpr, time)
\end{verbatim}

\subsubsection{Single-step Transition}

Since dereferencing an address becomes non-deterministic, our \texttt{atomicEval}
function also truns into non-deterministic. Given an atomic expression \texttt{e},
\texttt{atomicEval} returns a set of storable values, i.e., closures, to the caller.
If the expression is just a \texttt{lambda} term, then the returned set is singleton.

\begin{verbatim}
def atomicEval(e: Expr, env: Env, bstore: BStore): Set[Storable] = e match {
  case Var(x) => bstore(env(x))
  case lam@Lam(x, body) => Set(Clos(lam, env))
}
\end{verbatim}

The structure of function \texttt{step} is similar with concrete CESK machines, 
except non-determinism which makes \texttt{step} returns a list of reachable 
successor states.
In the beginning of \texttt{step}, we call function \texttt{tick} to update 
the time.
Then we have two cases to consider: 1) Current control expression is \texttt{Let},
and \texttt{App(f, ae)} is being bind to \texttt{x}.
Fristly we retrieve the set of closures that \texttt{f} may represents.
For each closure in the set, we do almost the same as what we did in concrete 
CESK machines. But note that since the continuation is allocated on store (\texttt{kstore}),
a new continuation address \texttt{new_kaddr} is constructed, and a new frame
\texttt{Frame(x, e, env)} paired with the current continuation address \texttt{kaddr}
is joined into this address. Finally, a list of states is generated.

2) An atomic expression \texttt{ae} sits on the control position of the state.
The value of \texttt{ae} is being returned to its caller. 
We dereference the continuation address \texttt{kaddr} and obtain a set of
continuations \texttt{conts}.
For each continuation in the set, we construct an environment based on the
environment of the frame (\texttt{env_f}), and bind \texttt{x} to a newly created binding 
address \texttt{baddr}; also update the store with \texttt{baddr} and 
the values that \texttt{ae} represents. In every generated states,
the control becomes the expression \texttt{e} in the frame,
and as we can tell from the name, continuation address \texttt{f_kaddr} 
also comes from the frame.

\begin{verbatim}
def step(s: State): List[State] = {
  val new_time = tick(s)
  s match {
    case State(Let(x, App(f, ae), e), env, bstore, kstore, kaddr, time) 
      if isAtomic(ae) =>
      val closures = atomicEval(f, env, bstore).toList
      for (Clos(Lam(v, body), env_c) <- closures) yield {
        val baddr = allocBind(v, new_time)
        val new_env = env_c + (v -> baddr)
        val new_bstore = bstore.update(baddr, atomicEval(ae, env, bstore))
        val new_kaddr = allocKont(body, new_time)
        val new_kstore = kstore.update(new_kaddr, Cont(Frame(x, e, env), kaddr))
        State(body, new_env, new_bstore, new_kstore, new_kaddr, new_time)
      }
    case State(ae, env, bstore, kstore, kaddr, time) 
      if isAtomic(ae) =>
      val conts = kstore(kaddr).toList
      for (Cont(Frame(x, e, env_f), f_kaddr) <- conts) yield {
        val baddr = allocBind(x, new_time)
        val new_env = env_f + (x -> baddr)
        val new_store = bstore.update(baddr, atomicEval(ae, env, bstore))
        State(e, new_env, new_store, kstore, f_kaddr, new_time)
      }
  }
}
\end{verbatim}

\subsubsection{$k$-call-sensitive Instantiation} \label{kcfainst}

\begin{verbatim}
def k: Int = 0
def tick(s: State): Time = (s.e::s.time).take(k)
\end{verbatim}

\subsubsection{Collecting Semantics}

To run (analyze) a program, as CESK machine, we use \texttt{inject} to construct
the initial state given a program. 
Note that the initial continuation store has a special mapping that maps continuation address
\texttt{Halt} to empty set of continuations.
We also provide an empty program contour as initial time.
\begin{verbatim}
def inject(e: Expr): State = 
  State(e, Map(), 
        Store[BAddr, Storable](Map()), 
        Store[KAddr, Cont](Map(Halt -> Set())), 
        Halt, List())
\end{verbatim}

However, comparing with concrete CESK machine, the
\texttt{drive} function performs collecting semantics instead of valuation
semantics. That is, for the purpose of analyzing programs, the function \texttt{drive}
collects all the intermediate machine states as the program is abstractly executing.
The following code shows a variant of work list algorithm that always applies \texttt{step}
function to the first element \texttt{hd} of the work list \texttt{todo} if \texttt{hd}
is unseen, then adds the result of \texttt{step} to the rest of work list and in 
the meanwhile adds \texttt{hd} to the explored states set.
If the work list is empty, the function just returns the set of reachable states up to now.

\begin{verbatim}
def drive(todo: List[State], seen: Set[State]): Set[State] = todo match {
  case Nil => seen
  case hd::tl if seen.contains(hd) => drive(tl, seen)
  case hd::tl => drive(step(hd).toList ++ tl, seen + hd)
}

def analyze(e: Expr): Set[State] = drive(List(inject(e)), Set())
\end{verbatim}

Finally, a user could use function \texttt{analyze} to obtain all reachable states 
for a given program.

%\subsection{Monadic Abstract Interpreter}
%Maybe not here?

\subsection{Pushdown Control-Flow Analysis}

Pushdown control-flow is a property in analysis that precisely models
the runtime call-stack of the analyzed program. 
A pushdown control-flow analysis provides as exact as runtime return-flow 
when analyzing the program, but traditional control-flow analysis collapse 
the state space using finite space abstraction thus cause imprecise stack modeling.

To see the problem of spurious return-flows, we can consider the following example:

\begin{verbatim}
(let ([id (lambda (z) z)])
  (let ([x (id 1)])
    (let ([y (id 2)])
      x)))
\end{verbatim}

In traditional $k$-CFA algorithm and the AAM we showed in section \ref{aam}, 
the return-flow of invocation \texttt{(id 2)} 
is going to both call-sites \texttt{(id 1)} and \texttt{(id 2)}. Therefore, the
returned value \texttt{2} for variable \texttt{y} is also propagated to 
variable \texttt{x} and then imprecise analysis result is arose.
This return-flow merging is inevitable even we increase the context-sensitivity.
If we use the monovariant analysis 0CFA, the analyzing result would be \texttt{x} and 
\texttt{y} point to set \texttt{\{1, 2\}}, because it not distinguishes
\texttt{z} at different call-sites.
Under $1$-CFA, the algorithm is able to distinguish that variable \texttt{z} of function
\texttt{id} has two different values at two call-sites, so variable \texttt{y} 
would not be polluted by \texttt{1}, but it is still helplessness for distinguish
return-flows.
TODO: do need more details to explain this example? (as in P4F paper)

In this section, we firstly show a simple but uncomputable solution to the
problem; then briefly review several recent research works that enable
computable and precise call/return match. Even though the first solution is
uncomputable, but as we will see in section 3, it is the starting point of our
transformation. 

\subsubsection{AAM with Unbound Stack}

A naive solution to is to use precise call stack modeling as we did in concrete
CESK machine. Instead of allocating continuations on store and recording an 
address of continuations, we leave the call stack unabstracted. 

In the definition of state \texttt{State}, continuation store disappears, and
\texttt{konts} becomes a list of frames. Other components keep the same.

\begin{verbatim}
case class State(e: Expr, env: Env, bstore: BStore, konts: List[Frame], time: Time)
\end{verbatim}

The state transition function \texttt{step} is still non-determinism, but
the only non-determinism happens when dereferencing the callee \texttt{f} 
from the store at call-site \texttt{App(f, ae)}. 
For each closure of \texttt{f} in the set, we do exactly
the same as what we did in concrete CESK machines: a new frame is constructed
and pushed onto the stack.
In the second case, since the continuation \texttt{konts} is a list of 
frames, we can simply decompose it to differentiate an empty stack
or a frame exists on the top of stack. 
If the stack is empty, then empty successors is returned, because the computation
is finished.
Otherwise, we matched a frame \texttt{Frame(x, e, env_f)}. 
This transition is deterministic, because we only have one frame, this frame
is then popped and the new state uses the rest of stack.

\begin{verbatim}
def step(s: State): List[State] = {
  val new_time = tick(s)
  s match {
    case State(Let(x, App(f, ae), e), env, bstore, konts, time) if isAtomic(ae) =>
      for (Clos(Lam(v, body), env_c) <- atomicEval(f, env, bstore).toList) yield {
        val frame = Frame(x, e, env)
        val baddr = allocBind(v, new_time)
        val new_env = env_c + (v -> baddr)
        val new_store = bstore.update(baddr, atomicEval(ae, env, bstore))
        State(body, new_env, new_store, frame::konts, new_time)
      }
    case State(ae, env, bstore, konts, time) if isAtomic(ae) =>
      konts match {
        case Nil => List()
        case Frame(x, e, env_f)::konts =>
          val baddr = allocBind(x, new_time)
          val new_env = env_f + (x -> baddr)
          val new_store = bstore.update(baddr, atomicEval(ae, env, bstore))
          List(State(e, new_env, new_store, konts, new_time))
      }
  }
}
\end{verbatim}

Unfortunately, even though other components is finite, this AAM with unbounded stack is uncomputable. 
Because the unbounded stack can grow to arbitrary deep and this implies that the state space is possibly 
infinite, therefore the analysis may not terminate for all programs if we simply enumerating 
reachable states.
To see this, consider a program that has two mutually recursived functions:

\begin{verbatim}
(letrec ([f1 (lambda (x) 
               (let ([x1 (f2 x)]) x1))]
         [f2 (lambda (y)
               (let ([y1 (f1 y)]) y1))])
  (let ([z (f1 1)])
    z))
\end{verbatim}

\texttt{f1} and \texttt{f2} call each others, and the stack will be interleaved
pushing \texttt{f1} and \texttt{f2} onto the top of current stack, but not existing 
two stack components are the same in the state space.

\subsubsection{Computable Solutions}

Recent years, there are great efforts \cite{vardoulakis2010cfa2, earl2012introspective, 
gilray2016pushdown, johnson2015abstracting} to achieve precise call/return 
match based on small-step AAM which is what we described in section \ref{aam}.

CFA2 is the first solution that solves the return-flows problem\cite{vardoulakis2010cfa2}.
But CFA2 has several drawbacks: it works only on continuation-passing style programs, 
and only allows monovariant analysis, in addition with an exponential time complexity.
TODO: summarize PDCFA, AAC, P4F

In the rest of this section, we take a closer look at the P4F which is the
state-of-art techniques to accomplish perfect call-stack precision on small-step
AAMs, and Abstracting De nitional Interpreters (ADI) that adpots another 
approach to pushdown control flow analysis.

\textbf{Pushdown for Free.}
\citeauthor{gilray2016pushdown} proposed a continuation address allocator for 
small-step abstracting abstract machine that is both easy to implement and
computational inexpensive.

\begin{verbatim}
case class P4FContAddr(tgt: Expr, tgtEnv: Env, time: Time) extends KAddr
def allocKont(tgtExpr: Expr, tgtEnv: Env, time: Time): KAddr = 
  P4FContAddr(tgtExpr, tgtEnv, time)
\end{verbatim}

\textbf{Abstracting Definitional Interpreters.}

On the other side, with the insight from Reynold that the defined language will inherit properties
from the defining language, \citeauthor{darais2017abstracting} construct abstracting 
definitional interpreters (ADI) that automatically inherit the pushdown control-flow 
property from the defining language.
TODO: connection to this paper.
TODO: although they establish pushdown control-flow analysis in different ways, 
is there a correspondence between different methods?


\section{From AAM to ADI}

We start from the AAM with unbounded stack.

\subsection{Fusing}

\subsection{Disentangling}

for plain direct-style, the apply handles more cases.

\subsection{Refunctionalization}

allocating continuations of defined language on the heap of defining language.

\subsubsection{First Try}

simply trun evaluation contexts into higher-order continuations

\subsubsection{Computable Refunctionalization}

fix point cache

%probably Store Widening \& Abstract Garbage Collection
%monadic
\subsection{Monadification: From Refunctionalized AAM to ADI}

For one direction, we can transform the refunctionalized AAM to abstracting definitional interpreter
by adding monads.

\subsection{Un-CPS: From Refunctionalized AAM to Direct Style}

We can transform the refunctionalized AAM to direct style, but explicitly use 
side effects such as assignment and mutation to handle collecting semantics and non-determinism.

\section{Refunctionalized AAM}

\subsection{Store Widening}

\subsection{Higher-Order Controls?}

TODO: analyze programs with call/cc, shift, reset.

\subsection{Precise Call/Return Match}

show the precision of stack

\subsection{Termination}

show that number of continuation is finite.

\subsection{Soundness}

\subsection{Complexity}

\section{Perspective}

\subsection{Defunctionalization}

specify higher-order definitional interpreters using first-order means (cite)

\subsection{Refunctionalization}

\section{Detour: Shiver's \textit{k}-CFA?}

\section{Related Work}

\section{Conclusion}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}

%% Bibliography
\bibliography{references}

%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
